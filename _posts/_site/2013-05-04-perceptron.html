<p>感知机是二分类的线性分类模型，其输入是实例的特征向量，输出为实例的类别。 感知机学习的目的是将训练数据进行线性划分的分离超平面，属于是判别模型。感知机学习采用基于误分类的损失函数，利用梯度下降法对损失函数进行极小化，最后得到感知机模型。</p>

<p><em>强调：</em>利用感知机学习策略进行训练的数据集要求必须是线性可分的，否则感知机学习算法不会收敛，迭代结果会发生震荡。</p>

<h1 id='__fxsignwxb'>. <em>分类模型：</em> $f(x)=sign(w<em>x+b)$</em></h1>

<h1 id='_min_wblwbsum_x_i_in_my_iwx_ib'>. <em>极小化损失函数，对应于误分类点到分离超平面的总距离：</em>$\min_{w,b}L(w,b)=-\sum_{{x}_{i} \in M}{y}_{i}(w<em>{x}_{i}+b)$</em></h1>

<h1 id='_'>. 学习算法：随机梯度下降</h1>

<h1 id='_k'>. 当训练集线性可分时，感知机学习算法是收敛的。其在训练集上的误分类次数k满足不等式：</h1>

<p>$k \preceq ( \frac{R}{\gamma} )^2$</p>

<p>Python代码：</p>

<p>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</p>

<h1 id='_codinggbk_'>-<em>- coding:gbk -</em>-</h1>

<h1 id='id1'>针对二维空间的感知机学习算法</h1>

<h1 id='_fx__signwxb'>感知机模型 f(x) = sign(w<em>x+b)</em></h1>

<h1 id='__lwb__ywxb'>学习策略 损失函数: L(w,b) = -y(w<em>x+b)</em></h1>

<h1 id='_'>学习算法 随即梯度下降</h1>

<h1 id='author_richard'>@author Richard</h1>

<h1 id='date_20130504'>@date 2013-05-04</h1>

<h1 id='id2'>定义感知机类</h1>

<p>class Perceptron #初始化类 #m_learnrate:学习率 m_w0:x0的权值 m_w1:x1的权值 m_b:常向量 def <strong>init</strong>(self,m_learnrate,m_w0,m_w1,m_b): self.m_learnrate = m_learnrate self.m_w0 = m_w0 self.m_w1 = m_w1 self.m_b = m_b</p>

<pre><code>#判断针对训练数据x，估测的模型与实际数据是否有误差 
#即判断损失函数L(w,b)是否为0 
def judgeHasError(self,x): 
    #如果表达式小于0，说明没有被正确分类 
    #即y*(w0*x0+w1*x1+b)&lt;0 
    result = x[2]*(x[0]*self.m_w0+x[1]*self.m_w1+self.m_b) 
    if result&lt;=0: 
        return False 
    else: 
        return True 

#有误差的话，调整模型参数 
def adjustParam(self,x): 
    #根据梯度下降法调整参数 
    self.m_w0 = self.m_w0 + self.m_learnrate*x[2]*x[0] 
    self.m_w1 = self.m_w1 + self.m_learnrate*x[2]*x[1] 
    self.m_b = self.m_b + self.m_learnrate*x[2] 
    return 

#训练数据集 
def trainData(self,data,num): 
    count = 0 
    isOver = False 
    while not isOver: 
        print &quot;w0  w1  b :&quot; +str(self.m_w0)+&quot; &quot;+str(self.m_w1)+&quot; &quot;+str(self.m_b) 
        for i in range(0,num): 
            if not self.judgeHasError(data[i]): 
                count = count+1 
                print &quot;调整次数：&quot;+ str(count) 
                self.adjustParam(data[i]) 
                isOver = False 
                break 
            else: 
                isOver = True 
    #打印最后的参数 
    print &quot;w0  w1  b :&quot; +str(self.m_w0)+&quot; &quot;+str(self.m_w1)+&quot; &quot;+str(self.m_b) </code></pre>

<p>if <strong>name</strong> == &#8216;__main__&#8217;: p = Perceptron(1,0,0,0) #data = <span><span>3,3,1</span>,<span>4,3,1</span>,<span>1,1,-1</span></span> data = <span><span>3,3,1</span>,<span>4,3,1</span>,<span>1,1,-1</span>,<span>2,2,-1</span>,<span>5,4,1</span>,<span>1,3,-1</span></span> p.trainData(data,6) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</p>

<p>(完)</p>
<hr />